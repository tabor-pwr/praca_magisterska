\chapter{Charakterystyka algorytmów uczenia maszynowego}
\section{Uczenie nadzorowane (Supervised Learning)}
Uczenie nadzorowane to technika, w której algorytm otrzymuje gotowy zestaw danych
z wcześniej określonymi etykietami i uczy się na ich podstawie predyktować etykiety dla nowych nieznanych danych.
Dane uczące zawierają zmienne wejściowe oraz zmienną predykowaną (etykietę).
Standardowy proces uczenia nadzorowanego obejmuje podział zbioru danych na zbiór
treningowy, walidacyjny oraz testowy. Trening polega na dopasowaniu parametrów modelu
do danych treningowych poprzez minimalizację funkcji straty, która mierzy różnicę
między przewidywaniami modelu a rzeczywistymi etykietami. Po zakończeniu treningu danych
model zostaje poddany ocenie na zbiorze walidacyjnym w celu doboru hiperparametrów oraz monitorowaniu uczenia maszynowego,
aby zapobiec przeuczeniu modelu. Ostateczna ocena odbywa się na zbiorze testowym na danych nieznanych dla modelu i na podstawie tego modelu określana
wartość dokładności, precyzji, recall, F1 (dla klasyfikacji) lub MSE, MAE (dla regresji)\citep{bishop2006,hastie2009}.
\subsection{Regresja liniowa (Linear Regression)}
Regresja liniowa to podstawowa technika statystyczna i uczenia maszynowego stosowana do modelowania zależności między zmienną zależną (predykowaną) a jedną lub więcej zmiennymi niezależnymi (cechami). Celem regresji liniowej jest znalezienie liniowej funkcji, która najlepiej opisuje związek między zmiennymi, umożliwiając przewidywanie wartości zmiennej zależnej na podstawie wartości zmiennych niezależnych.

\textbf{Regresja liniowa prosta.}
W przypadku pojedynczej zmiennej niezależnej model można opisać równaniem:
\begin{equation}
y = \alpha + \beta x + \varepsilon,
\end{equation}
gdzie \(y\) to zmienna zależna, \(x\) to zmienna niezależna, \(\alpha\) to wyraz wolny, \(\beta\) to współczynnik nachylenia linii regresji, a \(\varepsilon\) to składnik losowy (błąd modelu).

\textbf{Regresja wieloraka.}
Regresja wieloraka jest rozszerzeniem regresji prostej, poprzez używanie wielu zmiennych niezależnych. Zakłada się liniową zależność między zmienną zależną a kombinacją liniową zmiennych niezależnych:
\begin{equation}
y = \alpha + \sum_{i=1}^{p} \beta_i x_i + \varepsilon,
\end{equation}
gdzie \(y\) to zmienna zależna, \(\alpha\) to wyraz wolny, \(x_i\) to zmienne niezależne, \(\beta_i\) to współczynniki regresji określające wpływ danej zmiennej na zmienną zależną, a \(\varepsilon\) to składnik losowy (błąd modelu).

Celem algorytmu regresji (prostej i wielorakiej) jest znalezienie optymalnych wartości współczynników \(\beta_i\), które minimalizują błąd predykcji. Współczynniki można dobrać za pomocą różnych metod, jednak najczęściej stosuje się metodę najmniejszych kwadratów (OLS — Ordinary Least Squares), która minimalizuje sumę kwadratów różnic między rzeczywistymi a przewidywanymi wartościami zmiennej zależnej.

\textbf{Estymator OLS (macierzowy zapis).}
\begin{equation}\label{eq:ols}
\widehat{\boldsymbol{\beta}} = (X^\top X)^{-1} X^\top \mathbf{y}
\end{equation}

Wzór \eqref{eq:ols} to macierzowy zapis estymatora OLS. Wyjaśnienie:
\begin{itemize}
  \item \(X\) — macierz projektująca (design matrix) o wymiarach \(n\times p\) (lub \(n\times (p+1)\), jeśli dodano kolumnę jedynek dla wyrazu wolnego),  
  \item \(\mathbf{y}\) — wektor obserwacji o wymiarze \(n\times 1\),  
  \item \(\widehat{\boldsymbol{\beta}}\) — wektor estymowanych współczynników o wymiarze \(p\times 1\).
\end{itemize}

Aby wyrażenie było poprawne, macierz \(X^\top X\) musi być odwracalna (brak doskonałej multikolinearności). Przy klasycznych założeniach (m.in. \(E[\varepsilon]=0\), \(\text{Var}(\varepsilon)=\sigma^2 I\)) estymator jest nieobciążony, a jego wariancja wynosi \(\text{Var}(\widehat{\boldsymbol{\beta}})=\sigma^2 (X^\top X)^{-1}\). Gdy \(X^\top X\) jest źle uwarunkowana lub nieodwracalna, stosuje się regularyzację (np. Ridge) lub metody numeryczne (gradient descent, SVD)\citep{james2013}.

\vspace{0.5cm}

\textbf{Inne metody estymacji współczynników regresji liniowej:}
\begin{itemize}
    \item Metoda gradientu prostego (Gradient Descent) — iteracyjna metoda optymalizacji minimalizująca funkcję straty poprzez aktualizację współczynników w kierunku przeciwnym do gradientu \citep{bishop2006,murphy2012}.
    \item Metoda najmniejszych modułów (Least Absolute Deviations) — minimalizuje sumę bezwzględnych różnic między rzeczywistymi a przewidywanymi wartościami, co czyni ją bardziej odporną na wartości odstające \citep{birkes1993}. 
    \item Metoda Ridge Regression — wprowadza regularyzację L2, karę za duże wartości współczynników, co pomaga w radzeniu sobie z problemem multikolinearności i przeuczenia modelu \citep{hoerl1970,hastie2009}.
    \item Metoda Lasso Regression — regularyzacja L1, która może prowadzić do zerowania niektórych współczynników, skutkując modelem o mniejszej liczbie cech (automatyczny wybór cech) \citep{tibshirani1996}.
    \item Metoda Elastic Net — łączy regularyzację L1 i L2, co pozwala na lepsze dostosowanie modelu do danych \citep{zou2005}.
    \item Metoda SVD (Singular Value Decomposition) — rozkłada macierz projektującą na składniki, umożliwiając stabilne obliczenie współczynników regresji nawet w przypadku kolinearności cech \citep{golub1996,press2007}.
    \item Metoda Bayesian Regression — wykorzystuje podejście bayesowskie do estymacji współczynników, uwzględniając niepewność i priorytety w modelu \citep{gelman2006,bishop2006}.
    \item QR Decomposition — rozkłada macierz projektującą na iloczyn macierzy ortogonalnej i górnotrójkątnej, co umożliwia efektywne rozwiązanie układu równań regresji \citep{golub1996,press2007}.
\end{itemize}

\subsection{Regresja logistyczna (Logistic Regression)}
Regresja logistyczna to technika statystyczna i uczenia maszynowego stosowana do modelowania zależności między zmienną zależną a jedną lub więcej zmiennymi niezależnymi, gdy zmienna zależna przyjmuję wartości binarne (np. 0 lub 1, tak lub nie). Celem regresji logistycznej jest przewidywanie prawdopodobieństwa przynależności do jednej z dwóch klas na podstawie wartości zmiennych niezależnych.

\textbf{Model regresji logistycznej.}
Model regresji logistycznej można zapisać jako:
\begin{equation}
P(Y=1|X) = \sigma(\boldsymbol{\beta}^\top X) = \frac{1}{1 + e^{-\boldsymbol{\beta}^\top X}}
\end{equation}
gdzie:
\begin{itemize}
  \item \(P(Y=1|X)\) — prawdopodobieństwo, że zmienna zależna \(Y\) przyjmuje wartość 1, biorąc pod uwagę zmienne niezależne \(X\),
  \item \(\sigma(z)\) — funkcja sigmoidalna, która przekształca dowolną wartość rzeczywistą \(z\) w przedział (0, 1).
\end{itemize}

\textbf{Estymacja parametrów.}
Parametry modelu \(\boldsymbol{\beta}\) są estymowane za pomocą metody największej wiarygodności (Maximum Likelihood Estimation, MLE). Celem jest maksymalizacja funkcji wiarygodności:
\begin{equation}
L(\boldsymbol{\beta}) = \prod_{i=1}^{n} P(Y_i|X_i; \boldsymbol{\beta})
\end{equation}
co jest równoważne minimalizacji funkcji straty:
\begin{equation}
J(\boldsymbol{\beta}) = -\sum_{i=1}^{n} \left[ Y_i \log(P(Y_i|X_i; \boldsymbol{\beta})) + (1 - Y_i) \log(1 - P(Y_i|X_i; \boldsymbol{\beta})) \right]
\end{equation}

\textbf{Właściwości modelu.}
Model regresji logistycznej ma kilka istotnych właściwości:
\begin{itemize}
  \item Wynikiem modelu jest prawdopodobieństwo, co czyni go odpowiednim narzędziem do klasyfikacji binarnej.
  \item Model jest odporny na wartości odstające, ponieważ wykorzystuje funkcję sigmoidalną.
  \item Można go łatwo rozszerzyć na problemy wieloklasowe (np. regresja wielomianowa).
\end{itemize}

\subsection{\(k\)-Najbliższych Sąsiadów (k-Nearest Neighbors)}
Algorytm \(k\)-Najbliższych Sąsiadów umieszcza dane wejściowe w przestrzeni wielowymiarowej i klasyfikuje je na podstawie etykiet najbliższych sąsiadów w tej przestrzeni.
Przestrzeń jest definiowana przez cechy danych, zbiór danych posiadający \(x\) cech jest reprezentowany w \(x\)-wymiarowej przestrzeni.
Algorytm klasyfikując dany obiekt oblicza odległości między nim a wszystkimi innymi obiektami w przestrzeni, a następnie wybiera \(k\) najblizszych sąsiadów.
Wartość \(k\) jest ustalana ustalana przed rozpoczęciem działania algorytmu. Niska wartość parametru \(k\) jest bardziej podatna na szumy w danych, podczas gdy wysoka wartość \(k\) może prowadzić do nadmiernego uogólnienia modelu \citep{cover1967}.

\vspace{0.5cm}
Algorytm \(k\)-najbliższych sąsiadów może wykorzystywać różne metryki do obliczania odległości m.in:

\vspace{0.5cm}
\textbf{Metryka Euklidesowa:}
Najpowszechniejsza metryka używana do obliczania odległości między dwoma punktami w przestrzeni wielowymiarowej. Definiowana jest jako:
\begin{equation}
d(p, q) = \sqrt{\sum_{i=1}^{n} (p_i - q_i)^2}
\end{equation}
gdzie \(p\) i \(q\) to dwa punkty w przestrzeni, a \(n\) to liczba wymiarów. Wyliczanie odległości metryką euklidesową polega na policzeniu różnicy ogległości w każdym wymiarze dla dwóch punktów,
zsumowaniu kwadratów tych różnic, a następnie wyciągnięciu pierwiastka kwadratowego z tej sumy \citep{duda2001,bishop2006}.

\vspace{0.5cm}
\textbf{Metryka Manhattan:}
Metryka Manhattan, nazywana również metryką taksówkową lub L1, mierzy odległość miedzy dwoma punktami jako sumę watości bezwzględnych z różnic współżędnych.
Definiowana jest jako:
\begin{equation}
d(p, q) = \sum_{i=1}^{n} |p_i - q_i|
\end{equation}
gdzie \(p\) i \(q\) to dwa punkty w przestrzeni, a \(n\) to liczba wymiarów. Obliczana jest jest różnica wartości \(p\) i \(q\) dla każdego wymiaru, a następnie sumowane są wartości bezwzględne tych różnic \citep{duda2001}.

\vspace{0.5cm}
\textbf{Metryka Kosinusowa:}
Metryka Kosinusowa mierzy wyznacza odległość między dwoma punktami na podstawie wyliczonego kąta między nimi.
Definiowana jest jako:
\begin{equation}
d(p, q) = 1 - \frac{p \cdot q}{\|p\| \|q\|}
\end{equation}
gdzie \(p\) i \(q\) to dwa punkty w przestrzeni, \(p \cdot q\) to iloczyn skalarny wektorów \(p\) i \(q\), a \(\|p\|\) i \(\|q\|\) to normy (długości) tych wektorów.
Normy długości wektorów są obliczane jako pierwiastki kwadratowe z sumy kwadratów ich współrzędnych \citep{manning2008,bishop2006}.

\vspace{0.5cm}
\textbf{Metryka Minkowskiego:}
Metryka Minkowskiego jest uogólnieniem metryk Euklidesowej i Manhattan. Umożliwa regulowanie sposobu obliczania odległości poprzez parametr \(p\).
Definiowana jest jako:
\begin{equation}
d(p, q) = \left( \sum_{i=1}^{n} |
p_i - q_i|^p \right)^{\frac{1}{p}}
\end{equation}
gdzie \(p\) i \(q\) to dwa punkty w przestrzeni, \(n\) to liczba wymiarów, a \(p\) to parametr regulujący sposób obliczania odległości.
Dla \(p=1\) metryka Minkowskiego jest równoważna metryce Manhattan, a dla \(p=2\) jest równoważna metryce Euklidesowej \citep{hastie2009}.

\subsection{Drzewa decyzyjne (Decision Trees)}
Drzewa decyzyjne to algorytm uczenia maszynowego, która służy do podejmowania decyzji na podstawie zestawu reguł, które są reprezentowane w formie drzewa.
Drzewo decyzyjne składa się z korzenia, które jest cechą dzielącą dane na grupy, węzłów wewnętrznych, które reprezentują pytania dotyczące cech danych, oraz liści, które reprezentują ostateczne decyzje lub klasyfikacje.
Algorytm budowy drzewa decyzyjnego polega na iteracyjnym dzieleniu danych na podzbiory na podstawie cech, które najlepiej rozdzielają dane według określonego kryterium.
Drzewo decyzyjne jest budowane, aż wszystkie elementy w podzbiorze należą do tej samej klasy lub nie ma już cech do podziału, osiągnie maksymalną głębokość lub kiedy dalszy podział nie poprawia jakości klasyfikacji \citep{quinlan1986,breiman1984}.

\vspace{0.5cm}
Drzewo decyzyjne do wyboru najlepszego podziału danych może wykorzystywać różne kryteria, m.in:

\vspace{0.5cm}
\textbf{Entropia:}
Entropia jest miarą niepewności lub nieuporządkowania w zbiorze danych. Entropia jest wykorzystywana do oceny jakości podziału danych na podstaiwe cechy.
Definiowana jest jako:
\begin{equation} 
H(S) = - \sum_{i=1}^{c} p_i \log_2(p_i)
\end{equation}
gdzie \(S\) to zbiór danych, \(c\) to liczba klas, a \(p_i\) to proporcja elementów należących do klasy \(i\) w zbiorze \(S\).
Entropia obliczana jest jako suma iloczynów proporcji klas i logarytmów tych proporcji, a następnie mnożona przez -1 \citep{shannon1948,quinlan1986}.

\vspace{0.5cm}
\textbf{Wskaźnik Gini (Gini Impurity):}
Wskaźnik Gini mierzy prawdopodobieństwo błędnej klasyfikacji losowo wybranego elementu, gdyby został on oznaczony losowo według rozkładu etykiet w węźle. Im niższy wskaźnik Gini, tym bardziej jednorodny jest węzeł. Wskaźnik Gini dla zbioru \(S\) jest definiowany jako:
\begin{equation}
\text{Gini}(S) = 1 - \sum_{i=1}^{c} p_i^2
\end{equation}
gdzie \(c\) to liczba klas, a \(p_i\) to proporcja przykładów w klasie \(i\). Wskaźnik Gini jest używany w algorytmie CART (Classification and Regression Trees) ze względu na swoją prostotę obliczeniową i dobrą wydajność \citep{breiman1984}.

\vspace{0.5cm}
\textbf{Zysk informacji (Information Gain):}
Zysk informacji mierzy redukcję entropii osiągniętą przez podział zbioru danych według danego atrybutu. Jest to różnica między entropią zbioru nadrzędnego a ważoną sumą entropii zbiorów potomnych. Zysk informacji dla atrybutu \(A\) w zbiorze \(S\) definiuje się jako:
\begin{equation}
\text{IG}(S, A) = H(S) - \sum_{v \in \text{Values}(A)} \frac{|S_v|}{|S|} H(S_v)
\end{equation}
gdzie \(\text{Values}(A)\) to zbiór wszystkich możliwych wartości atrybutu \(A\), \(S_v\) to podzbiór \(S\), dla którego atrybut \(A\) ma wartość \(v\), a \(H(S)\) to entropia zbioru. Algorytm ID3 wybiera atrybut o największym zysku informacji \citep{quinlan1986}.

\vspace{0.5cm}
\textbf{Współczynnik zysku (Gain Ratio)}
Współczynnik zysku jest modyfikacją zysku informacji, która koryguje tendencję do faworyzowania atrybutów o wielu wartościach. Normalizuje zysk informacji przez podzielenie go przez tzw. split information, która mierzy szerokość i jednolitość podziału. Współczynnik zysku dla atrybutu \(A\) w zbiorze \(S\) definiuje się jako:
\begin{equation}
\text{GainRatio}(S, A) = \frac{\text{IG}(S, A)}{\text{SplitInfo}(S, A)}
\end{equation}
gdzie \(\text{IG}(S, A)\) to zysk informacji dla atrybutu \(A\), a \(\text{SplitInfo}(S, A)\) to informacja o podziale, definiowana jako:
\begin{equation}
\text{SplitInfo}(S, A) = -\sum_{v \in \text{Values}(A)} \frac{|S_v|}{|S|} \log_2\left(\frac{|S_v|}{|S|}\right)
\end{equation}
gdzie \(\text{Values}(A)\) to zbiór wszystkich możliwych wartości atrybutu \(A\), \(S_v\) to podzbiór \(S\) zawierający elementy, dla których atrybut \(A\) ma wartość \(v\), \(|S_v|\) to liczba elementów w podzbiorze \(S_v\), a \(|S|\) to całkowita liczba elementów w zbiorze \(S\). Informacja o podziale mierzy, jak bardzo atrybut dzieli dane. Im bardziej równomierny podział, tym wyższa wartość \(\text{SplitInfo}\), co zmniejsza współczynnik zysku i zapobiega faworyzowaniu atrybutów o wielu unikalnych wartościach. Współczynnik zysku jest używany w algorytmie C4.5 jako ulepszona wersja ID3 \citep{quinlan1993}.

\vspace{0.5cm}
\textbf{Redukcja wariancji (Variance Reduction)}
Redukcja wariancji jest kryterium stosowanym w drzewach regresyjnych, gdzie celem jest przewidywanie wartości ciągłych, a nie kategorii. Kryterium to wybiera podział, który maksymalnie redukuje wariancję wartości docelowych w węzłach potomnych. Redukcja wariancji dla podziału zbioru \(S\) na podzbiory \(S_{\text{left}}\) i \(S_{\text{right}}\) definiuje się jako:
\begin{equation}
\text{VarReduction}(S) = \text{Var}(S) - \left(\frac{|S_{\text{left}}|}{|S|} \text{Var}(S_{\text{left}}) + \frac{|S_{\text{right}}|}{|S|} \text{Var}(S_{\text{right}})\right)
\end{equation}
gdzie \(\text{Var}(S)\) oznacza wariancję wartości docelowych w zbiorze \(S\). Algorytm CART dla regresji wykorzystuje to kryterium do budowy drzew regresyjnych \citep{breiman1984}.

\subsection{Las losowy (Random Forest)}
Las losowy to algorytm uczenia maszynowego, który łączy wiele drzew decyzyjnych w celu poprawy dokładności przewidywań i redukcji przeuczenia.
Algorytm ten działa na zasadzie tworzenia wielu niezależnych drzew decyzyjnych, z których każde jest trenowane na losowym podzbiorze danych i losowym podzbiorze cech.
Ostateczna predykcja lasu losowego jest uzyskiwana przez agregację wyników wszystkich drzew. 
Dla klasyfikacji stosuje się głosowanie większościowe, a dla regresji średnią arytmetyczną \citep{breiman2001}.

\vspace{0.5cm}
Las losowy uczy się poprzez losowanie i budowanie wielu drzew decyzyjnych.
Każde drzewo dostaje losowy podzbiór danych treningowych oraz losowy podzbiór cech do rozważenia przy każdym podziale węzła.
Ten proces losowania danych i cech wprowadza różnorodność między drzewami, co przekłada się na lepszą ogólną wydajność modelu.
Poszczególne drzewa dzielone są na podstawie kryteriów omówionych w sekcji dotyczącej drzew decyzyjnych, takich jak entropia, wskaźnik Gini czy zysk informacji \citep{breiman2001}.

\vspace{0.5cm}
Dodatkowo przy budownie lasu losowego dobiera się parametry:

\vspace{0.5cm}
\begin{table}[ht]
\centering
\caption{Podstawowe hiperparametry lasu losowego}
\label{tab:rf_params}
\begin{tabular}{|l|p{10cm}|}
\hline
\textbf{Parametr} & \textbf{Opis} \\
\hline
Liczba drzew (\(B\)) & Liczba drzew decyzyjnych w lesie. Większa liczba zazwyczaj poprawia wydajność, ale zwiększa czas obliczeń. \\
\hline
Maksymalna głębokość & Maksymalna głębokość każdego drzewa. Ograniczenie głębokości może zapobiec przeuczeniu. \\
\hline
Liczba cech (\(m\)) & Liczba losowo wybranych cech rozważanych przy każdym podziale. Typowo \(m = \sqrt{p}\) dla klasyfikacji lub \(m = p/3\) dla regresji. (p to liczba wszystkich cech) \\
\hline
Minimalna liczba próbek & Minimalna liczba próbek wymagana do podziału węzła wewnętrznego lub do utworzenia liścia. \\
\hline
Bootstrap & Czy stosować bootstrap sampling (losowanie ze zwracaniem) do tworzenia podzbiorów treningowych. \\
\hline
\end{tabular}
\end{table}

Strojenie hiperparametrów lasu losowego, jest zadaniem człowieka, ale najczęściej wykorzystuje się metody automatyczne do testowania.

\vspace{0.5cm}
\textbf{Grid Search (przeszukiwanie siatki)}
Grid Search polega na przeszukiwaniu wszystkich możliwych kombinacji hiperparametrów z wcześniej zdefiniowanej siatki wartości.
Dla każdej kombinacji algorytm trenuje model i ocenia jego wydajność za pomocą walidacji krzyżowej.
Następnie wybiera zestaw parametrów dający najlepsze wyniki według ustalonej metryki (np. accuracy, F1).

\vspace{0.5cm}
\textbf{Randomized Search (przeszukiwanie losowe)}
Randomized Search jest wariantem Grid Search, który zamiast sprawdzać wszystkie kombinacje, losowo próbkuje określoną liczbę zestawów hiperparametrów z zadanych rozkładów.
Użytkownik definiuje budżet iteracji (liczbę kombinacji do przetestowania).

\vspace{0.5cm}
\textbf{Optuna}
Optuna to framework do optymalizacji hiperparametrów wykorzystujący zaawansowane algorytmy, takie jak Tree-structured Parzen Estimator (TPE). W przeciwieństwie do metod grid i random search, Optuna adaptacyjnie wybiera kolejne kombinacje hiperparametrów na podstawie wyników wcześniejszych prób — uczy się, które obszary przestrzeni są obiecujące i koncentruje tam przeszukiwanie. Framework oferuje elastyczność w definiowaniu przestrzeni parametrów, wbudowane wizualizacje oraz możliwość przycinania nieobiecujących prób (pruning). Optuna wykazuje szybszą zbieżność niż metody losowe, ale wymaga instalacji dodatkowej biblioteki \citep{akiba2019}.

\vspace{0.5cm}
\textbf{Bayesian Optimization (optymalizacja bayesowska)}
Bayesian Optimization buduje probabilistyczny model zastępczy (surrogate model), zazwyczaj Gaussian Process, który aproksymuje funkcję celu (np. dokładność modelu jako funkcję hiperparametrów). Na podstawie tego modelu algorytm wybiera kolejne punkty do próbkowania za pomocą funkcji akwizycji (acquisition function), takiej jak Expected Improvement (EI), która balansuje eksplorację nowych obszarów przestrzeni i eksploatację obiecujących regionów. Metoda jest szczególnie efektywna, gdy ewaluacja funkcji celu jest kosztowna (np. trening dużych modeli), ponieważ wymaga stosunkowo małej liczby iteracji. Wadą jest złożoność implementacji oraz spowolnienie dla bardzo dużych przestrzeni hiperparametrów \citep{snoek2012}.

\vspace{0.5cm}
\textbf{AutoML (Automated Machine Learning)}
AutoML automatyzuje cały proces budowy modelu uczenia maszynowego, w tym wybór algorytmu, inżynierię cech, dobór hiperparametrów oraz tworzenie modeli ensemble. Narzędzia takie jak Auto-sklearn, TPOT czy H2O AutoML wykorzystują kombinację technik optymalizacji (bayesian optimization, evolutionary algorithms) oraz meta-learning (wiedza z wcześniejszych eksperymentów na podobnych zbiorach). Główną zaletą AutoML jest minimalna interwencja użytkownika — wystarczy dostarczyć dane i określić metrykę, a system samodzielnie buduje i optymalizuje model. Wadą jest ograniczona kontrola nad procesem, długie czasy obliczeń oraz potencjalne tworzenie skomplikowanych, trudnych do interpretacji modeli typu „czarna skrzynka" \citep{feurer2015,olson2016}.